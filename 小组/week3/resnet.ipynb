{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-11T05:29:05.288713Z",
     "start_time": "2025-04-11T03:06:23.287643Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "#设置随机种子\n",
    "torch.manual_seed(12046)\n",
    "#数据准备（CIFAR10专用）\n",
    "transform_train=transforms.Compose([\n",
    "    transforms.RandomCrop(32,padding=4),#随意裁剪图像\n",
    "    transforms.RandomHorizontalFlip(),#随机水平翻转\n",
    "    transforms.ToTensor(),#转为张量\n",
    "    transforms.Normalize((0.4914,0.4822,0.4465),(0.2470,0.2435,0.2616)),#归一化，这里使用的是针对这个数据集的均值和标准差\n",
    "])\n",
    "\n",
    "transform_test=transforms.Compose([#测试集的预处理\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914,0.4822,0.4465),(0.2470,0.2435,0.2616)),\n",
    "])\n",
    "\n",
    "#加载数据集，并且将预处理部分应用进来\n",
    "train_set=datasets.CIFAR10(root='./data',train=True,download=True,transform=transform_train)\n",
    "test_set=datasets.CIFAR10(root='./data',train=False,download=True,transform=transform_test)\n",
    "#划分验证集，比例为9：1\n",
    "train_size=int(0.9*len(train_set))\n",
    "val_size=len(train_set)-train_size\n",
    "train_set,val_set=torch.utils.data.random_split(train_set,[train_size,val_size])\n",
    "# 创建DataLoader\n",
    "batch_size=128#每个批次数据量为128\n",
    "train_loader=DataLoader(train_set,batch_size=batch_size,shuffle=True,num_workers=2)\n",
    "val_loader=DataLoader(val_set,batch_size=batch_size,shuffle=False,num_workers=2)\n",
    "test_loader=DataLoader(test_set,batch_size=batch_size,shuffle=False,num_workers=2)\n",
    "\n",
    "# 残差块\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self,in_channel,out_channel,stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv2d(in_channel,out_channel,kernel_size=3,stride=stride,padding=1,bias=False)\n",
    "        self.bn1=nn.BatchNorm2d(out_channel)\n",
    "        self.conv2=nn.Conv2d(out_channel,out_channel,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.bn2=nn.BatchNorm2d(out_channel)\n",
    "        #下采样模块\n",
    "        self.downsample=nn.Sequential()\n",
    "        if stride!=1 or in_channel!=out_channel:\n",
    "            self.downsample=nn.Sequential(\n",
    "                nn.Conv2d(in_channel,out_channel,kernel_size=1,stride=stride,bias=False),\n",
    "                nn.BatchNorm2d(out_channel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity=self.downsample(x)\n",
    "        out=F.relu(self.bn1(self.conv1(x)))\n",
    "        out=self.bn2(self.conv2(out))\n",
    "        out+=identity\n",
    "        out=F.relu(out)\n",
    "        return out\n",
    "\n",
    "#CIFAR10的ResNet\n",
    "class ResNet_CIFAR10(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #初始层\n",
    "        self.conv1=nn.Conv2d(3, 64, kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.bn1=nn.BatchNorm2d(64)\n",
    "\n",
    "        # 残差块组4个阶段\n",
    "        self.layer1=self._make_layer(64,64,stride=1)\n",
    "        self.layer2=self._make_layer(64,128,stride=2)\n",
    "        self.layer3=self._make_layer(128,256,stride=2)\n",
    "        self.layer4=self._make_layer(256,512,stride=2)\n",
    "\n",
    "        # 分类头\n",
    "        self.avgpool=nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc=nn.Linear(512,10)\n",
    "\n",
    "    def _make_layer(self,in_channels,out_channels,stride):\n",
    "        return nn.Sequential(\n",
    "            ResidualBlock(in_channels,out_channels,stride),\n",
    "            ResidualBlock(out_channels,out_channels,stride=1)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.bn1(self.conv1(x)))  #[B,64,32,32]\n",
    "        x=self.layer1(x)  #[B,64,32,32]\n",
    "        x=self.layer2(x)  #[B,128,16,16]\n",
    "        x=self.layer3(x)  # [B,256,8,8]\n",
    "        x=self.layer4(x)  # [B,512,4,4]\n",
    "        x =self.avgpool(x)  #[B,512,1,1]\n",
    "        x=torch.flatten(x,1)  #[B,512]\n",
    "        x=self.fc(x)  #[B,10]\n",
    "        return x\n",
    "\n",
    "# 训练工具函数\n",
    "def estimate_loss(model,data_loader,eval_iters=10):\n",
    "    model.eval()\n",
    "    losses=[]\n",
    "    accuracies=[]\n",
    "    for i,(inputs,labels) in enumerate(data_loader):\n",
    "        if i>=eval_iters: break\n",
    "        with torch.no_grad():\n",
    "            logits=model(inputs)\n",
    "            loss=F.cross_entropy(logits,labels)\n",
    "            _,predicted=torch.max(logits,1)\n",
    "            acc=(predicted==labels).float().mean()\n",
    "        losses.append(loss.item())\n",
    "        accuracies.append(acc.item())\n",
    "    model.train()\n",
    "    return {\n",
    "        'loss': sum(losses)/len(losses),\n",
    "        'accuracy': sum(accuracies)/len(accuracies)\n",
    "    }\n",
    "\n",
    "def train(model,optimizer,epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for inputs,labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            logits=model(inputs)\n",
    "            loss=F.cross_entropy(logits,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # 评估\n",
    "        train_stats=estimate_loss(model,train_loader)\n",
    "        val_stats =estimate_loss(model,val_loader)\n",
    "        test_stats=estimate_loss(model,test_loader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        print(f\"Train Loss: {train_stats['loss']:.4f} | Val Loss: {val_stats['loss']:.4f} | Test Loss: {test_stats['loss']:.4f}\")\n",
    "        print(f\"Train Acc: {train_stats['accuracy']:.4f} | Val Acc: {val_stats['accuracy']:.4f} | Test Acc: {test_stats['accuracy']:.4f}\")\n",
    "        print(\"-\"*50)\n",
    "\n",
    "#训练模型\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model=ResNet_CIFAR10().to(device)\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001,weight_decay=1e-4)\n",
    "# 将DataLoader移到设备（如果使用GPU）\n",
    "train_loader=DataLoader(train_set,batch_size=batch_size,shuffle=True,num_workers=2,pin_memory=True)\n",
    "val_loader=DataLoader(val_set,batch_size=batch_size,shuffle=False,num_workers=2,pin_memory=True)\n",
    "test_loader=DataLoader(test_set,batch_size=batch_size,shuffle=False,num_workers=2,pin_memory=True)\n",
    "# 开始训练\n",
    "train(model,optimizer,epochs=20)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Train Loss: 1.4973 | Val Loss: 1.5177 | Test Loss: 1.5295\n",
      "Train Acc: 0.4766 | Val Acc: 0.4711 | Test Acc: 0.4766\n",
      "--------------------------------------------------\n",
      "Epoch 2/20\n",
      "Train Loss: 1.1512 | Val Loss: 1.1509 | Test Loss: 1.2242\n",
      "Train Acc: 0.6094 | Val Acc: 0.6062 | Test Acc: 0.5844\n",
      "--------------------------------------------------\n",
      "Epoch 3/20\n",
      "Train Loss: 0.8376 | Val Loss: 0.8531 | Test Loss: 0.9066\n",
      "Train Acc: 0.7055 | Val Acc: 0.7031 | Test Acc: 0.6758\n",
      "--------------------------------------------------\n",
      "Epoch 4/20\n",
      "Train Loss: 0.8637 | Val Loss: 0.9130 | Test Loss: 0.8641\n",
      "Train Acc: 0.7250 | Val Acc: 0.6937 | Test Acc: 0.7242\n",
      "--------------------------------------------------\n",
      "Epoch 5/20\n",
      "Train Loss: 0.6087 | Val Loss: 0.6669 | Test Loss: 0.6659\n",
      "Train Acc: 0.7992 | Val Acc: 0.7922 | Test Acc: 0.7922\n",
      "--------------------------------------------------\n",
      "Epoch 6/20\n",
      "Train Loss: 0.6765 | Val Loss: 0.7283 | Test Loss: 0.8303\n",
      "Train Acc: 0.7602 | Val Acc: 0.7445 | Test Acc: 0.7211\n",
      "--------------------------------------------------\n",
      "Epoch 7/20\n",
      "Train Loss: 0.5067 | Val Loss: 0.5901 | Test Loss: 0.5797\n",
      "Train Acc: 0.8266 | Val Acc: 0.7875 | Test Acc: 0.7953\n",
      "--------------------------------------------------\n",
      "Epoch 8/20\n",
      "Train Loss: 0.4767 | Val Loss: 0.4619 | Test Loss: 0.5477\n",
      "Train Acc: 0.8320 | Val Acc: 0.8391 | Test Acc: 0.8141\n",
      "--------------------------------------------------\n",
      "Epoch 9/20\n",
      "Train Loss: 0.4647 | Val Loss: 0.4868 | Test Loss: 0.5686\n",
      "Train Acc: 0.8398 | Val Acc: 0.8344 | Test Acc: 0.8117\n",
      "--------------------------------------------------\n",
      "Epoch 10/20\n",
      "Train Loss: 0.3796 | Val Loss: 0.4446 | Test Loss: 0.4521\n",
      "Train Acc: 0.8633 | Val Acc: 0.8562 | Test Acc: 0.8477\n",
      "--------------------------------------------------\n",
      "Epoch 11/20\n",
      "Train Loss: 0.4364 | Val Loss: 0.5270 | Test Loss: 0.5714\n",
      "Train Acc: 0.8469 | Val Acc: 0.8227 | Test Acc: 0.8273\n",
      "--------------------------------------------------\n",
      "Epoch 12/20\n",
      "Train Loss: 0.3783 | Val Loss: 0.4932 | Test Loss: 0.5535\n",
      "Train Acc: 0.8727 | Val Acc: 0.8313 | Test Acc: 0.8227\n",
      "--------------------------------------------------\n",
      "Epoch 13/20\n",
      "Train Loss: 0.3212 | Val Loss: 0.4763 | Test Loss: 0.4688\n",
      "Train Acc: 0.8992 | Val Acc: 0.8484 | Test Acc: 0.8398\n",
      "--------------------------------------------------\n",
      "Epoch 14/20\n",
      "Train Loss: 0.3038 | Val Loss: 0.4356 | Test Loss: 0.4752\n",
      "Train Acc: 0.8844 | Val Acc: 0.8625 | Test Acc: 0.8492\n",
      "--------------------------------------------------\n",
      "Epoch 15/20\n",
      "Train Loss: 0.3576 | Val Loss: 0.4290 | Test Loss: 0.4210\n",
      "Train Acc: 0.8719 | Val Acc: 0.8625 | Test Acc: 0.8484\n",
      "--------------------------------------------------\n",
      "Epoch 16/20\n",
      "Train Loss: 0.3488 | Val Loss: 0.4180 | Test Loss: 0.4589\n",
      "Train Acc: 0.8797 | Val Acc: 0.8523 | Test Acc: 0.8586\n",
      "--------------------------------------------------\n",
      "Epoch 17/20\n",
      "Train Loss: 0.2828 | Val Loss: 0.4169 | Test Loss: 0.3911\n",
      "Train Acc: 0.9078 | Val Acc: 0.8695 | Test Acc: 0.8703\n",
      "--------------------------------------------------\n",
      "Epoch 18/20\n",
      "Train Loss: 0.2215 | Val Loss: 0.3382 | Test Loss: 0.3159\n",
      "Train Acc: 0.9250 | Val Acc: 0.8891 | Test Acc: 0.8852\n",
      "--------------------------------------------------\n",
      "Epoch 19/20\n",
      "Train Loss: 0.3000 | Val Loss: 0.4150 | Test Loss: 0.4543\n",
      "Train Acc: 0.9008 | Val Acc: 0.8680 | Test Acc: 0.8531\n",
      "--------------------------------------------------\n",
      "Epoch 20/20\n",
      "Train Loss: 0.2029 | Val Loss: 0.3504 | Test Loss: 0.3484\n",
      "Train Acc: 0.9289 | Val Acc: 0.8812 | Test Acc: 0.8719\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
